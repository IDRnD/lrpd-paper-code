{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-dq445c3u because the default path (/home/iiakovlev/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ssdraid0cgpu01/home/iiakovlev/new-pipeline/audio-pipelines-pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import torch\n",
    "import resampy\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Dict, List\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "from collections import defaultdict\n",
    "pipeline_root = Path().resolve().parents[0]\n",
    "print(pipeline_root)\n",
    "sys.path.append(str(pipeline_root)) # adding pipeline root to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import EER\n",
    "from torch.utils.data import DataLoader\n",
    "import datautils.parsing.antispoofing as parsing\n",
    "from models.utils import load_weights_from_pl_pipeline\n",
    "from models.model_builders import AudioClassificationModel\n",
    "from datautils.dataset import Dataset, simple_collate_func, DummyAugmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(dicts : List[Dict[int,List]]):\n",
    "    merged = {}\n",
    "    for d in dicts:\n",
    "        for k,v in d.items():\n",
    "            if k in merged:\n",
    "                merged[k].extend(v)\n",
    "            else:\n",
    "                merged[k] = v\n",
    "    return merged\n",
    "\n",
    "def flatten_dict(d : Dict[int,List]):\n",
    "    flattened = []\n",
    "    for k,v in d.items():\n",
    "        flattened.extend(zip(v,[k]*len(v)))\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_setup = yaml.safe_load((pipeline_root / 'data.yml').read_text())\n",
    "ASVSPOOF2017 = Path(data_setup['asv17_root'])\n",
    "LRPD = Path(data_setup['lrpd_root'])\n",
    "\n",
    "asv17_dev = flatten_dict(parsing.parse_asv17(**{\n",
    "    \"asv_spoof_root\": str(ASVSPOOF2017),\n",
    "    \"part\": \"dev\",\n",
    "    \"return_as\": \"dict\"\n",
    "}))\n",
    "\n",
    "asv17_eval = flatten_dict(parsing.parse_asv17(**{\n",
    "    \"asv_spoof_root\": str(ASVSPOOF2017),\n",
    "    \"part\": \"eval\",\n",
    "    \"return_as\": \"dict\"\n",
    "}))\n",
    "\n",
    "lrpd_eval = flatten_dict(merge_dicts([parsing.parse_dir(root,label) for root,label in [\n",
    "    (LRPD/\"source_val\",0),\n",
    "    (LRPD/\"val_aparts\",1),\n",
    "]]))\n",
    "\n",
    "datasets = {\n",
    "    \"asv17_dev\" : asv17_dev,\n",
    "    \"asv17_eval\" : asv17_eval,\n",
    "    \"lrpd_eval\" : lrpd_eval\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/media/ssdraid0cgpu01/home/iiakovlev/new-pipeline/audio-pipelines-pytorch/checkpoints/antispoofing/lrpd_office_lrpd_aparts'),\n",
      " PosixPath('/media/ssdraid0cgpu01/home/iiakovlev/new-pipeline/audio-pipelines-pytorch/checkpoints/antispoofing/asv17_train'),\n",
      " PosixPath('/media/ssdraid0cgpu01/home/iiakovlev/new-pipeline/audio-pipelines-pytorch/checkpoints/antispoofing/lrpd_office_lrpd_aparts_asv17_train')]\n"
     ]
    }
   ],
   "source": [
    "model_dirs = list((pipeline_root/\"checkpoints/antispoofing\").glob(\"*/\"))\n",
    "pprint(model_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir):\n",
    "    model_config = json.loads((model_dir/\"model_config.json\").read_text())\n",
    "    model = AudioClassificationModel(**model_config)\n",
    "    model = model.eval()\n",
    "    weights_path = str(model_dir/\"model.ckpt\")\n",
    "    load_weights_from_pl_pipeline(model,str(weights_path),remove_unessacary=False,strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "def simple_collate_func(batch):\n",
    "    xs, ys = list(zip(*batch))\n",
    "    xs = np.stack(xs)\n",
    "    ys = np.stack(ys)\n",
    "    xs = torch.from_numpy(xs)\n",
    "    return xs,ys\n",
    "\n",
    "def run_prediction(model, data : List[Tuple[Path,str]],utt_len_sec=3.0):\n",
    "    val_dataset = Dataset(\n",
    "        data=data,\n",
    "        size=None,\n",
    "        augmentor=DummyAugmentor(),\n",
    "        utt_len_sec=utt_len_sec,\n",
    "        samplerate=16000,\n",
    "        convert_to_ohe=False\n",
    "    )\n",
    "\n",
    "    val_dl = DataLoader(dataset=val_dataset,\n",
    "        batch_size=128, shuffle=False, sampler=None,\n",
    "        batch_sampler=None, num_workers=10, collate_fn=simple_collate_func,\n",
    "        pin_memory=True, drop_last=False, timeout=0,\n",
    "        worker_init_fn=None, multiprocessing_context=None\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dl):\n",
    "            x, y = batch\n",
    "            x = x.cuda()\n",
    "            pred = torch.nn.functional.softmax(model(x),dim=-1)\n",
    "            labels.extend(y)\n",
    "            predictions.append(pred.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions)\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unexpected_keys : []\n",
      "missing_keys : []\n",
      "created ds with : 1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:03<00:00,  3.52it/s]\n",
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrpd_office_lrpd_aparts | asv17_dev | EER : 27.84%\n",
      "unexpected_keys : []\n",
      "missing_keys : []\n",
      "created ds with : 13306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:08<00:00, 12.85it/s]\n",
      "  0%|          | 0/1580 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrpd_office_lrpd_aparts | asv17_eval | EER : 17.18%\n",
      "unexpected_keys : []\n",
      "missing_keys : []\n",
      "created ds with : 202165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1580/1580 [03:31<00:00,  7.48it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrpd_office_lrpd_aparts | lrpd_eval | EER : 0.16%\n",
      "unexpected_keys : []\n",
      "missing_keys : []\n",
      "created ds with : 1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  6.25it/s]\n",
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asv17_train | asv17_dev | EER : 17.54%\n",
      "unexpected_keys : []\n",
      "missing_keys : []\n",
      "created ds with : 13306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:08<00:00, 12.99it/s]\n",
      "  0%|          | 0/1580 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asv17_train | asv17_eval | EER : 13.94%\n",
      "unexpected_keys : []\n",
      "missing_keys : []\n",
      "created ds with : 202165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1580/1580 [03:31<00:00,  7.49it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asv17_train | lrpd_eval | EER : 21.70%\n",
      "unexpected_keys : []\n",
      "missing_keys : []\n",
      "created ds with : 1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  6.09it/s]\n",
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrpd_office_lrpd_aparts_asv17_train | asv17_dev | EER : 18.63%\n",
      "unexpected_keys : []\n",
      "missing_keys : []\n",
      "created ds with : 13306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:08<00:00, 12.86it/s]\n",
      "  0%|          | 0/1580 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrpd_office_lrpd_aparts_asv17_train | asv17_eval | EER : 11.91%\n",
      "unexpected_keys : []\n",
      "missing_keys : []\n",
      "created ds with : 202165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1580/1580 [03:31<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrpd_office_lrpd_aparts_asv17_train | lrpd_eval | EER : 0.28%\n"
     ]
    }
   ],
   "source": [
    "all_predictions = dict()\n",
    "for model_dir in model_dirs:\n",
    "    model_name = model_dir.parts[-1]\n",
    "    all_predictions[model_name] = {}\n",
    "    for dataset_name, files in datasets.items():\n",
    "        model = load_model(model_dir)\n",
    "        labels, predictions = run_prediction(model,files)\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        eer = EER(labels,predictions[:,1])[0]\n",
    "        all_predictions[model_name][dataset_name] = eer\n",
    "        print(f\"{model_name} | {dataset_name} | EER : {eer*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(list)\n",
    "model_names = list(all_predictions.keys())\n",
    "ds_names = list(datasets.keys())\n",
    "for model_name  in model_names:\n",
    "    for ds_name in ds_names:\n",
    "        data[ds_name].append(all_predictions[model_name][ds_name])\n",
    "df = pd.DataFrame(data=data)\n",
    "df.index = model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ab56f_ th {\n",
       "          border: 1px black solid !important;\n",
       "    }#T_ab56f_row0_col0{\n",
       "            color:  black !important;\n",
       "            border:  1px black solid !important;\n",
       "            background-color:  #fc7f00;\n",
       "            color:  #000000;\n",
       "        }#T_ab56f_row0_col1{\n",
       "            color:  black !important;\n",
       "            border:  1px black solid !important;\n",
       "            background-color:  #ffaf00;\n",
       "            color:  #000000;\n",
       "        }#T_ab56f_row0_col2{\n",
       "            color:  black !important;\n",
       "            border:  1px black solid !important;\n",
       "            background-color:  #e4ff78;\n",
       "            color:  #000000;\n",
       "        }#T_ab56f_row1_col0{\n",
       "            color:  black !important;\n",
       "            border:  1px black solid !important;\n",
       "            background-color:  #ffae00;\n",
       "            color:  #000000;\n",
       "        }#T_ab56f_row1_col1{\n",
       "            color:  black !important;\n",
       "            border:  1px black solid !important;\n",
       "            background-color:  #ffbd00;\n",
       "            color:  #000000;\n",
       "        }#T_ab56f_row1_col2{\n",
       "            color:  black !important;\n",
       "            border:  1px black solid !important;\n",
       "            background-color:  #ff9c00;\n",
       "            color:  #000000;\n",
       "        }#T_ab56f_row2_col0{\n",
       "            color:  black !important;\n",
       "            border:  1px black solid !important;\n",
       "            background-color:  #ffa900;\n",
       "            color:  #000000;\n",
       "        }#T_ab56f_row2_col1{\n",
       "            color:  black !important;\n",
       "            border:  1px black solid !important;\n",
       "            background-color:  #ffc908;\n",
       "            color:  #000000;\n",
       "        }#T_ab56f_row2_col2{\n",
       "            color:  black !important;\n",
       "            border:  1px black solid !important;\n",
       "            background-color:  #e5fe77;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_ab56f_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >asv17_dev</th>        <th class=\"col_heading level0 col1\" >asv17_eval</th>        <th class=\"col_heading level0 col2\" >lrpd_eval</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ab56f_level0_row0\" class=\"row_heading level0 row0\" >lrpd_office_lrpd_aparts</th>\n",
       "                        <td id=\"T_ab56f_row0_col0\" class=\"data row0 col0\" >27.84%</td>\n",
       "                        <td id=\"T_ab56f_row0_col1\" class=\"data row0 col1\" >17.18%</td>\n",
       "                        <td id=\"T_ab56f_row0_col2\" class=\"data row0 col2\" >0.16%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab56f_level0_row1\" class=\"row_heading level0 row1\" >asv17_train</th>\n",
       "                        <td id=\"T_ab56f_row1_col0\" class=\"data row1 col0\" >17.54%</td>\n",
       "                        <td id=\"T_ab56f_row1_col1\" class=\"data row1 col1\" >13.94%</td>\n",
       "                        <td id=\"T_ab56f_row1_col2\" class=\"data row1 col2\" >21.70%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ab56f_level0_row2\" class=\"row_heading level0 row2\" >lrpd_office_lrpd_aparts_asv17_train</th>\n",
       "                        <td id=\"T_ab56f_row2_col0\" class=\"data row2 col0\" >18.63%</td>\n",
       "                        <td id=\"T_ab56f_row2_col1\" class=\"data row2 col1\" >11.91%</td>\n",
       "                        <td id=\"T_ab56f_row2_col2\" class=\"data row2 col2\" >0.28%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3f19227820>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import cm\n",
    "cm = cm.get_cmap('Wistia')\n",
    "df.style.set_properties(\n",
    "    **{'color': 'black !important',\n",
    "       'border': '1px black solid !important'}\n",
    ").set_table_styles([{\n",
    "    'selector': 'th',\n",
    "    'props': [('border', '1px black solid !important')]\n",
    "}]\n",
    ").format(\"{:.2%}\").background_gradient(cmap=cm,vmin=0.0,vmax=df.values.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt1.7",
   "language": "python",
   "name": "pt1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
